{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "246df837-6a69-4f26-8647-4b2330a58f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7b55df-98a9-4326-97e9-3c93f7655d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71375b17-1d94-4eb5-9424-a0334be13cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ac526c-d3bc-4499-8722-4143d6e63a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a055a59a-e26e-4119-b700-74940c3003b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "cnn.add(Conv2D(64,(3,3),input_shape=(64,64,3),activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33aa9ef-1a6e-45cd-aeea-f336dafda86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(32,(3,3),activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be52d4ef-0a7c-4c94-afe5-a06fed820e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(64,activation='relu'))\n",
    "cnn.add(Dense(32,activation='relu'))\n",
    "cnn.add(Dense(16,activation='relu'))\n",
    "cnn.add(Dense(8,activation='relu'))\n",
    "cnn.add(Dense(4,activation='relu'))\n",
    "cnn.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ce4ca04-6595-4624-98bc-d86709f69e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1acbb7eb-bd11-49d1-8f8d-05386902f72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 557 images belonging to 2 classes.\n",
      "Found 140 images belonging to 2 classes.\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  18/1000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:25\u001b[0m 453ms/step - loss: 0.6998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 12ms/step - loss: 0.6966 - val_loss: 0.6965\n",
      "Epoch 2/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - loss: 0.6963 - val_loss: 0.6931\n",
      "Epoch 3/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.6937 - val_loss: 0.6930\n",
      "Epoch 4/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.6930 - val_loss: 0.6927\n",
      "Epoch 5/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.6928 - val_loss: 0.6929\n",
      "Epoch 6/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.6957 - val_loss: 0.6928\n",
      "Epoch 7/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.6942 - val_loss: 0.6926\n",
      "Epoch 8/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.6929 - val_loss: 0.6924\n",
      "Epoch 9/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.6934 - val_loss: 0.6979\n",
      "Epoch 10/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.6956 - val_loss: 0.6928\n",
      "Epoch 11/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.6934 - val_loss: 0.6932\n",
      "Epoch 12/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - loss: 0.6932 - val_loss: 0.6932\n",
      "Epoch 13/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.6943 - val_loss: 0.6932\n",
      "Epoch 14/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - loss: 0.6930 - val_loss: 0.6932\n",
      "Epoch 15/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.6932 - val_loss: 0.6918\n",
      "Epoch 16/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - loss: 0.7037 - val_loss: 0.6923\n",
      "Epoch 17/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.6924 - val_loss: 0.6915\n",
      "Epoch 18/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - loss: 0.6910 - val_loss: 0.6919\n",
      "Epoch 19/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 0.6894 - val_loss: 0.6918\n",
      "Epoch 20/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 0.6880 - val_loss: 0.6916\n",
      "Epoch 21/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.6872 - val_loss: 0.6888\n",
      "Epoch 22/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.6850 - val_loss: 0.6812\n",
      "Epoch 23/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.6803 - val_loss: 0.6802\n",
      "Epoch 24/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.6806 - val_loss: 0.6929\n",
      "Epoch 25/25\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 0.6729 - val_loss: 0.6775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16deb08e780>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\yrohi\\train\",\n",
    "        target_size=(64,64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        r\"C:\\Users\\yrohi\\test\",\n",
    "        target_size=(64,64),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "cnn.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=1000,\n",
    "        epochs=25,\n",
    "        validation_data=test_generator)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7237997-ef4b-4725-bad6-f20d0faff105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f32bbfc1-b2b9-475a-b8ae-f2e76bdb33a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.load_img(r\"C:\\Users\\yrohi\\Downloads\\cat.jpeg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c317eb0d-aa8f-4c8c-b80d-180b719f6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2bf32f9-fdde-40e4-bb55-e720ce760406",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=np.expand_dims(img,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e1c2e1b-0eca-446f-a982-14783df5960e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.2076423e-12]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=cnn.predict(img)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bfea1f5-e272-4bea-9ed5-9969184af99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat\n"
     ]
    }
   ],
   "source": [
    "if p>0.5:\n",
    "    print(\"Dog\")\n",
    "else:\n",
    "    print(\"Cat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
